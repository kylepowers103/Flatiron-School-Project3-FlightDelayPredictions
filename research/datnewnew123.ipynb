{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:54:32.325611Z",
     "start_time": "2019-01-13T23:54:32.307937Z"
    }
   },
   "outputs": [],
   "source": [
    "#RUNPCA \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "# Imputing missing values and scaling values\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pickle \n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, SCORERS\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:54:35.334448Z",
     "start_time": "2019-01-13T23:54:35.330804Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:00:43.506430Z",
     "start_time": "2019-01-14T00:00:41.268183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>description</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Flights</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DepartureDelayGroups</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>SchedDepartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>273.207333</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IAD</td>\n",
       "      <td>556.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>540</td>\n",
       "      <td>534.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>EV3268</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>272.990000</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>656.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700</td>\n",
       "      <td>594.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>AA17</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>272.990000</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>644.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>645</td>\n",
       "      <td>762.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DL886</td>\n",
       "      <td>645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>272.990000</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>654.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>655</td>\n",
       "      <td>404.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DL1818</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>272.990000</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CLT</td>\n",
       "      <td>658.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700</td>\n",
       "      <td>226.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>US461</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Day  hour  pressure  humidity  temperature  wind_direction  \\\n",
       "0  2015.0    1.0  1.0     5    1043.0      80.0   273.207333           317.0   \n",
       "1  2015.0    1.0  1.0     6    1043.0      80.0   272.990000           329.0   \n",
       "2  2015.0    1.0  1.0     6    1043.0      80.0   272.990000           329.0   \n",
       "3  2015.0    1.0  1.0     6    1043.0      80.0   272.990000           329.0   \n",
       "4  2015.0    1.0  1.0     6    1043.0      80.0   272.990000           329.0   \n",
       "\n",
       "   wind_speed   description Origin  Flights Dest  DepTime  DepDelay  \\\n",
       "0         1.0    few clouds    ATL      1.0  IAD    556.0      16.0   \n",
       "1         1.0  sky is clear    ATL      1.0  MIA    656.0      -4.0   \n",
       "2         1.0  sky is clear    ATL      1.0  LGA    644.0      -1.0   \n",
       "3         1.0  sky is clear    ATL      1.0  MCO    654.0      -1.0   \n",
       "4         1.0  sky is clear    ATL      1.0  CLT    658.0      -2.0   \n",
       "\n",
       "   DepDelayMinutes  DepDel15  CRSDepTime  Distance  DepartureDelayGroups  \\\n",
       "0             16.0       1.0         540     534.0                   1.0   \n",
       "1              0.0       0.0         700     594.0                  -1.0   \n",
       "2              0.0       0.0         645     762.0                  -1.0   \n",
       "3              0.0       0.0         655     404.0                  -1.0   \n",
       "4              0.0       0.0         700     226.0                  -1.0   \n",
       "\n",
       "   TaxiOut  TaxiIn  ArrTime  ArrDelay  Cancelled  Diverted  AirTime  Distance  \\\n",
       "0      9.0    15.0    739.0      14.0        0.0       0.0     79.0     534.0   \n",
       "1     15.0     9.0    842.0     -10.0        0.0       0.0     82.0     594.0   \n",
       "2     31.0     9.0    901.0       8.0        0.0       0.0     97.0     762.0   \n",
       "3     14.0     8.0    815.0      -7.0        0.0       0.0     59.0     404.0   \n",
       "4     15.0    10.0    801.0     -11.0        0.0       0.0     38.0     226.0   \n",
       "\n",
       "   CarrierDelay  WeatherDelay  NASDelay  SecurityDelay  LateAircraftDelay  \\\n",
       "0           0.0           0.0       0.0            0.0                0.0   \n",
       "1           0.0           0.0       0.0            0.0                0.0   \n",
       "2           0.0           0.0       0.0            0.0                0.0   \n",
       "3           0.0           0.0       0.0            0.0                0.0   \n",
       "4           0.0           0.0       0.0            0.0                0.0   \n",
       "\n",
       "   CancellationCode FlightNum  SchedDepartTime  \n",
       "0                 0    EV3268            540.0  \n",
       "1                 0      AA17            660.0  \n",
       "2                 0     DL886            645.0  \n",
       "3                 0    DL1818            655.0  \n",
       "4                 0     US461            660.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"./dataframe.csv\")\n",
    "df = pd.read_pickle(\"dataframe.pkl\")\n",
    "df.head() # shape = (278220, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:01:01.159301Z",
     "start_time": "2019-01-14T00:01:01.098724Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df[['DepDelay','hour', 'pressure', 'humidity', 'temperature', 'wind_speed', 'description', 'Origin', 'Dest', 'DepTime', 'Distance', 'ArrTime','AirTime']]\n",
    "X=df[['hour', 'pressure', 'humidity', 'temperature', 'wind_speed', 'description', 'Origin', 'Dest', 'DepTime', 'Distance', 'ArrTime','AirTime']]\n",
    "y = df['DepDelay']\n",
    "# 'DepTime' 'ArrTime' 'AirTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:02:53.448303Z",
     "start_time": "2019-01-14T00:02:52.437249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Origin_ATL</th>\n",
       "      <th>Origin_CLT</th>\n",
       "      <th>Origin_DEN</th>\n",
       "      <th>Origin_DFW</th>\n",
       "      <th>Origin_ORD</th>\n",
       "      <th>Dest_ABE</th>\n",
       "      <th>Dest_ABI</th>\n",
       "      <th>Dest_ABQ</th>\n",
       "      <th>Dest_ABY</th>\n",
       "      <th>Dest_ACT</th>\n",
       "      <th>Dest_AEX</th>\n",
       "      <th>Dest_AGS</th>\n",
       "      <th>Dest_ALB</th>\n",
       "      <th>...</th>\n",
       "      <th>description_freezing rain</th>\n",
       "      <th>description_haze</th>\n",
       "      <th>description_heavy intensity drizzle</th>\n",
       "      <th>description_heavy intensity rain</th>\n",
       "      <th>description_heavy snow</th>\n",
       "      <th>description_light intensity drizzle</th>\n",
       "      <th>description_light rain</th>\n",
       "      <th>description_light snow</th>\n",
       "      <th>description_mist</th>\n",
       "      <th>description_moderate rain</th>\n",
       "      <th>description_overcast clouds</th>\n",
       "      <th>description_proximity shower rain</th>\n",
       "      <th>description_proximity thunderstorm</th>\n",
       "      <th>description_scattered clouds</th>\n",
       "      <th>description_sky is clear</th>\n",
       "      <th>description_smoke</th>\n",
       "      <th>description_snow</th>\n",
       "      <th>description_thunderstorm</th>\n",
       "      <th>description_thunderstorm with rain</th>\n",
       "      <th>description_very heavy rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.454565</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.105299</td>\n",
       "      <td>0.105299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.450220</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.118828</td>\n",
       "      <td>0.118828</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.450220</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.156708</td>\n",
       "      <td>0.156708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.450220</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.450220</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.035851</td>\n",
       "      <td>0.035851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  pressure  humidity  temperature  wind_speed  Distance  Distance  \\\n",
       "0  0.217391  0.826446  0.784946     0.454565    0.058824  0.105299  0.105299   \n",
       "1  0.260870  0.826446  0.784946     0.450220    0.058824  0.118828  0.118828   \n",
       "2  0.260870  0.826446  0.784946     0.450220    0.058824  0.156708  0.156708   \n",
       "3  0.260870  0.826446  0.784946     0.450220    0.058824  0.075986  0.075986   \n",
       "4  0.260870  0.826446  0.784946     0.450220    0.058824  0.035851  0.035851   \n",
       "\n",
       "   Origin_ATL  Origin_CLT  Origin_DEN  Origin_DFW  Origin_ORD  Dest_ABE  \\\n",
       "0           1           0           0           0           0         0   \n",
       "1           1           0           0           0           0         0   \n",
       "2           1           0           0           0           0         0   \n",
       "3           1           0           0           0           0         0   \n",
       "4           1           0           0           0           0         0   \n",
       "\n",
       "   Dest_ABI  Dest_ABQ  Dest_ABY  Dest_ACT  Dest_AEX  Dest_AGS  Dest_ALB  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "              ...               description_freezing rain  description_haze  \\\n",
       "0             ...                                       0                 0   \n",
       "1             ...                                       0                 0   \n",
       "2             ...                                       0                 0   \n",
       "3             ...                                       0                 0   \n",
       "4             ...                                       0                 0   \n",
       "\n",
       "   description_heavy intensity drizzle  description_heavy intensity rain  \\\n",
       "0                                    0                                 0   \n",
       "1                                    0                                 0   \n",
       "2                                    0                                 0   \n",
       "3                                    0                                 0   \n",
       "4                                    0                                 0   \n",
       "\n",
       "   description_heavy snow  description_light intensity drizzle  \\\n",
       "0                       0                                    0   \n",
       "1                       0                                    0   \n",
       "2                       0                                    0   \n",
       "3                       0                                    0   \n",
       "4                       0                                    0   \n",
       "\n",
       "   description_light rain  description_light snow  description_mist  \\\n",
       "0                       0                       0                 0   \n",
       "1                       0                       0                 0   \n",
       "2                       0                       0                 0   \n",
       "3                       0                       0                 0   \n",
       "4                       0                       0                 0   \n",
       "\n",
       "   description_moderate rain  description_overcast clouds  \\\n",
       "0                          0                            0   \n",
       "1                          0                            0   \n",
       "2                          0                            0   \n",
       "3                          0                            0   \n",
       "4                          0                            0   \n",
       "\n",
       "   description_proximity shower rain  description_proximity thunderstorm  \\\n",
       "0                                  0                                   0   \n",
       "1                                  0                                   0   \n",
       "2                                  0                                   0   \n",
       "3                                  0                                   0   \n",
       "4                                  0                                   0   \n",
       "\n",
       "   description_scattered clouds  description_sky is clear  description_smoke  \\\n",
       "0                             0                         0                  0   \n",
       "1                             0                         1                  0   \n",
       "2                             0                         1                  0   \n",
       "3                             0                         1                  0   \n",
       "4                             0                         1                  0   \n",
       "\n",
       "   description_snow  description_thunderstorm  \\\n",
       "0                 0                         0   \n",
       "1                 0                         0   \n",
       "2                 0                         0   \n",
       "3                 0                         0   \n",
       "4                 0                         0   \n",
       "\n",
       "   description_thunderstorm with rain  description_very heavy rain  \n",
       "0                                   0                            0  \n",
       "1                                   0                            0  \n",
       "2                                   0                            0  \n",
       "3                                   0                            0  \n",
       "4                                   0                            0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features123=X\n",
    "categorical_subset = features123[['Origin','Dest','description']]\n",
    "numeric_subset=features123[['hour', 'pressure', 'humidity', 'temperature', 'wind_speed', 'Distance']]\n",
    "numeric_subset_columns=['hour', 'pressure', 'humidity', 'temperature', 'wind_speed', 'Distance']\n",
    "# One hot encode\n",
    "\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "#normalize categorical \n",
    "numeric_subset = numeric_subset[numeric_subset_columns].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "# numeric_subset\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features1234 = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "features1234.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:03:20.112293Z",
     "start_time": "2019-01-14T00:03:20.108684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 278220 entries, 0 to 50722\n",
      "Columns: 285 entries, hour to description_very heavy rain\n",
      "dtypes: float64(7), uint8(278)\n",
      "memory usage: 90.7 MB\n"
     ]
    }
   ],
   "source": [
    "features1234.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:03:26.085558Z",
     "start_time": "2019-01-14T00:00:49.368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278220, 285)\n",
      "(278220,)\n",
      "(278220,)\n"
     ]
    }
   ],
   "source": [
    "features = features1234 #(278220, 13)\n",
    "targets = y #pd.DataFrame(y)  #278220,)\n",
    "y_value=y\n",
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "print(y_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:03:26.187892Z",
     "start_time": "2019-01-14T00:00:50.126Z"
    }
   },
   "outputs": [],
   "source": [
    "### changed to calculate just with depdelay\n",
    "###Convert y to set of classes\n",
    "\n",
    "\n",
    "\n",
    "# y_ontime = y[(y <= 15) & (y >= 0)] # 0 <= y <= 15 is on time by FAA standards\n",
    "# y_early = y[y < 0] # y < 0 is flight left early\n",
    "# y_delay = y[(y > 15) & (y <= 60)] # 15 < y <= 60 we'll consider as delayed\n",
    "# y_sig_delay = (y[y > 60]) # 60 < y we'll considered significantly delayed\n",
    "\n",
    "# y_early = [\"y_early\"]*len(y_early)\n",
    "# y_ontime = ['y_ontime']*len(y_ontime)\n",
    "# y_delay = ['y_delay']*len(y_delay)\n",
    "# y_sig_delay = ['y_sig_delay']*len(y_sig_delay)\n",
    "# y = pd.DataFrame(y_early + y_ontime + y_delay + y_sig_delay)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(y)\n",
    "# # y = column(y, warn=True)\n",
    "# y_new = le.transform(y)\n",
    "# y_new.shape #(278220,)\n",
    "# y_new\n",
    "# targets=y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278220, 285)\n",
      "(278220,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T00:03:26.287811Z",
     "start_time": "2019-01-14T00:00:51.150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into 70% training and 30% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:54:18.878830Z",
     "start_time": "2019-01-13T23:54:18.871337Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12) #Starter code\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "print(model_log) #Preview model params\n",
    "\n",
    "#Predict\n",
    "# y_pred = logreg.predict(X_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all metrics below\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# # Classification Report\n",
    "# from sklearn.metrics import classification_report \n",
    "# print(classification_report(y_test, y_pred))\n",
    "# # Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test, y_pred))\n",
    "# y_pred 0.90      0.90      0.90     83466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_test, y_pred))\n",
    "# feature importance\n",
    "# for feature in zip(features_names, rf.feature_importances_):\n",
    "#     print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Newstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:56:10.147343Z",
     "start_time": "2019-01-13T23:55:00.013Z"
    }
   },
   "outputs": [],
   "source": [
    "def classification_model(model, x_train, x_test, y_train, y_test):\n",
    "    model_ = model\n",
    "    model_.fit(x_train, y_train)\n",
    "    y_hat_test = model_.predict(x_test)\n",
    "    model_y_score = model_.decision_function(x_test)\n",
    "#     model_y_score = model_.predict_proba(x_test)[:, 0]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, model_y_score)\n",
    "    return model_, fpr, tpr, thresholds, y_hat_test\n",
    "def Print_confusion_matrix():\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    true_negative  = cm[0,0]\n",
    "    true_positive  = cm[1,1]\n",
    "    false_negative = cm[1,0]\n",
    "    false_positive = cm[0,1]\n",
    "#     tpr = true_positive/(true_positive + false_negative)\n",
    "#     fpr = false_positive/(false_positive + true_negative)\n",
    "    total = true_negative + true_positive + false_negative + false_positive\n",
    "    accuracy = (true_positive + true_negative)/total\n",
    "    precision = (true_positive)/(true_positive + false_positive)\n",
    "    recall = (true_positive)/(true_positive + false_negative)\n",
    "    misclassification_rate = (false_positive + false_negative)/total\n",
    "    F1 = (2*true_positive)/(2*true_positive + false_positive + false_negative)\n",
    "    print('accuracy.................%7.4f' % accuracy)\n",
    "    print('precision................%7.4f' % precision)\n",
    "    print('recall...................%7.4f' % recall)\n",
    "    print('F1.......................%7.4f' % F1)\n",
    "    print('auc......................%7.4f' % auc(fpr, tpr))\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    print('AUC: {}'.format(metrics.auc(fpr, tpr)))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-13T22:33:49.036Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = len(features.columns)\n",
    "#Logistic Regression\n",
    "param_grid1 = {'C': [0.001, 0.01] }\n",
    "\n",
    "#Random Forest\n",
    "param_grid2 = {\"n_estimators\": range(20, 100, 2),\n",
    "                  \"max_depth\": range(4, 40, 2),\n",
    "                  \"min_samples_leaf\": range(2, 100, 2),\n",
    "                  \"max_features\": range(1, n_features+1),\n",
    "                  \"min_samples_split\": range(2, 10),\n",
    "                  \"bootstrap\": [True],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "#Gradient Boost\n",
    "param_grid3 = {'n_estimators': [100],\n",
    "                  'learning_rate':[0.1],\n",
    "                  'max_depth': [40]}\n",
    "\n",
    "#XGBoost\n",
    "param_grid4 = {'min_child_weight': [1, 5, 10],\n",
    "                   'learning_rate':[0.001, 0.01,0.1],\n",
    "                   'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                   'subsample': [0.6, 0.8, 1.0],\n",
    "                   'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                   'max_depth': [3, 4, 5]}\n",
    "\n",
    "#AdaBoost\n",
    "param_grid5 = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                   'learning_rate':[0.001, 0.01],\n",
    "                   \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "                   \"n_estimators\": [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-13T22:55:44.947Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def grid_search(clf, param_grid):\n",
    "    global best_model, saved_model\n",
    "    cv = ShuffleSplit(n_splits = 15, test_size = 0.20, random_state = 2)\n",
    "    n_iter_search = 70\n",
    "    estimator = GridSearchCV(clf,\n",
    "                                   param_grid = param_grid,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   verbose = 0,\n",
    "                                   cv = cv,\n",
    "                                   n_jobs = 3)\n",
    "        \n",
    "    fit = estimator.fit(x_train, y_train)\n",
    "    \n",
    "    best_model = estimator.best_estimator_\n",
    "    print('\\nbest_model:\\n', best_model)\n",
    "\n",
    "#     print('\\nFeature Importances:', best_model.feature_importances_)\n",
    "    \n",
    "    y_predicted = best_model.predict(x_train)\n",
    "    probabilities = best_model.predict_proba(x_test)\n",
    "    y_score = best_model.decision_function(x_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_score)\n",
    "    \n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "    c_report = classification_report(y_train, y_predicted)\n",
    "    print('\\nClassification report:\\n', c_report)\n",
    "    return best_model, fit, probabilities, c_report, fpr, tpr, thresholds\n",
    "def grid_search2(clf, param_grid):\n",
    "    global best_model, saved_model\n",
    "    cv = ShuffleSplit(n_splits = 15, test_size = 0.20, random_state = 2)\n",
    "    n_iter_search = 70\n",
    "    estimator = GridSearchCV(clf,\n",
    "                                   param_grid = param_grid,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   verbose = 0,\n",
    "                                   cv = cv,\n",
    "                                   n_jobs = 3)\n",
    "        \n",
    "    fit = estimator.fit(x_resampled, y_resampled)\n",
    "    \n",
    "    best_model1 = estimator.best_estimator_\n",
    "    print('\\nbest_model:\\n', best_model1)\n",
    "\n",
    "#     print('\\nFeature Importances:', best_model.feature_importances_)\n",
    "    \n",
    "    y_predicted = best_model1.predict(x_resampled)\n",
    "    probabilities = best_model1.predict_proba(x_test)\n",
    "    y_score = best_model1.decision_function(x_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_score)\n",
    "    \n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "    c_report = classification_report(y_resampled, y_predicted)\n",
    "    print('\\nClassification report:\\n', c_report)\n",
    "    return best_model1, fit, probabilities, c_report, fpr, tpr, thresholds\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "x_train,x_test=X_train,X_test\n",
    "\n",
    "start_time = timer(None)\n",
    "grid_search(LogisticRegression(class_weight = 'balanced'), param_grid1)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T22:25:02.625894Z",
     "start_time": "2019-01-13T22:25:02.615253Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier (has decision function)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start_time = timer(None)\n",
    "grid_search2(AdaBoostClassifier(base_estimator= DecisionTreeClassifier()), param_grid5)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timer(None)\n",
    "grid_search2(GradientBoostingClassifier(), param_grid3)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomforest Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:39:50.255791Z",
     "start_time": "2019-01-13T23:39:24.565319Z"
    }
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(random_state=60)\n",
    "random_forest_mae = fit_and_evaluate(random_forest)\n",
    "\n",
    "print('Random Forest Regression Performance on the test set: MAE = %0.4f' % random_forest_mae)\n",
    "# Random Forest Regression Performance on the test set: MAE = 0.0023\n",
    "# random_forest_mae.feature_importances_\n",
    "random_forest.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:57:38.224420Z",
     "start_time": "2019-01-13T23:57:38.045113Z"
    }
   },
   "outputs": [],
   "source": [
    "#view the features and their importances\n",
    "rf=random_forest\n",
    "feature_names = np.asarray(random_forest.get_params)\n",
    "for feature in zip(features_names, rf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (4 Features) Model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T03:40:32.068610Z",
     "start_time": "2019-01-12T03:37:53.894935Z"
    }
   },
   "outputs": [],
   "source": [
    "gradient_boosted = GradientBoostingRegressor(random_state=60)\n",
    "gradient_boosted_mae = fit_and_evaluate(gradient_boosted)\n",
    "print('Gradient Boosted Regression Performance on the test set: MAE = %0.4f' % gradient_boosted_mae)\n",
    "#Gradient Boosted Regression Performance on the test set: MAE = 0.2731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T08:28:58.162303Z",
     "start_time": "2019-01-12T08:28:57.912570Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_mae = fit_and_evaluate(knn)\n",
    "print('K-Nearest Neighbors Regression Performance on the test set: MAE = %0.4f' % knn_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newmodels to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:59:19.619767Z",
     "start_time": "2019-01-13T23:59:03.856277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# digits = datasets.load_digits()\n",
    "X_digits = features\n",
    "y_digits = targets\n",
    "\n",
    "###############################################################################\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_digits)\n",
    "\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(pca.explained_variance_, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')\n",
    "\n",
    "###############################################################################\n",
    "# Prediction\n",
    "\n",
    "n_components = [20, 40, 64]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs))\n",
    "estimator.fit(features, targets)\n",
    "\n",
    "plt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,\n",
    "            linestyle=':', label='n_components chosen')\n",
    "plt.legend(prop=dict(size=12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T09:37:26.942786Z",
     "start_time": "2019-01-12T09:37:26.870Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['hour', 'pressure', 'humidity', 'temperature', 'wind_speed', 'Distance']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['Origin','Dest','description']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "X = features\n",
    "y = targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T06:11:22.508197Z",
     "start_time": "2019-01-12T06:11:22.490505Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T03:31:44.115201Z",
     "start_time": "2019-01-12T03:30:03.717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function to be optimized\n",
    "loss = ['ls', 'lad', 'huber']\n",
    "\n",
    "# Number of trees used in the boosting process\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "\n",
    "# Maximum depth of each tree\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "\n",
    "# Minimum number of samples per leaf\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "# Minimum number of samples to split a node\n",
    "min_samples_split = [2, 4, 6, 10]\n",
    "\n",
    "# Maximum number of features to consider for making splits\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {'loss': loss,\n",
    "                       'n_estimators': n_estimators,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}\n",
    "# Create the model to use for hyperparameter tuning\n",
    "model = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                               param_distributions=hyperparameter_grid,\n",
    "                               cv=4, n_iter=25, \n",
    "                               scoring = 'neg_mean_absolute_error',\n",
    "                               n_jobs = -1, verbose = 1, \n",
    "                               return_train_score = True,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T03:31:44.126545Z",
     "start_time": "2019-01-12T03:30:05.058Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-12T02:37:50.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"./dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because running a model took too long, we decided to manually select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-12T02:37:51.025Z"
    }
   },
   "outputs": [],
   "source": [
    "# #all classifiers \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = features\n",
    "y = targets\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "C = 10\n",
    "kernel = 1.0 * RBF([1.0, 1.0])  # for GPC\n",
    "\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "                                      solver='saga',\n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=10000),\n",
    "    'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "                                                    solver='saga',\n",
    "                                                    multi_class='multinomial',\n",
    "                                                    max_iter=10000),\n",
    "    'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "                                            solver='saga',\n",
    "                                            multi_class='ovr',\n",
    "                                            max_iter=10000),\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
    "                      random_state=0),\n",
    "    'GPC': GaussianProcessClassifier(kernel)\n",
    "}\n",
    "\n",
    "n_classifiers = len(classifiers)\n",
    "\n",
    "plt.figure(figsize=(3 * 2, n_classifiers * 2))\n",
    "plt.subplots_adjust(bottom=.2, top=.95)\n",
    "\n",
    "xx = np.linspace(3, 9, 100)\n",
    "yy = np.linspace(1, 5, 100).T\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "Xfull = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "\n",
    "    # View probabilities:\n",
    "    probas = classifier.predict_proba(Xfull)\n",
    "    n_classes = np.unique(y_pred).size\n",
    "    for k in range(n_classes):\n",
    "        plt.subplot(n_classifiers, n_classes, index * n_classes + k + 1)\n",
    "        plt.title(\"Class %d\" % k)\n",
    "        if k == 0:\n",
    "            plt.ylabel(name)\n",
    "        imshow_handle = plt.imshow(probas[:, k].reshape((100, 100)),\n",
    "                                   extent=(3, 9, 1, 5), origin='lower')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        idx = (y_pred == k)\n",
    "        if idx.any():\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='w', edgecolor='k')\n",
    "\n",
    "ax = plt.axes([0.15, 0.04, 0.7, 0.05])\n",
    "plt.title(\"Probability\")\n",
    "plt.colorbar(imshow_handle, cax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
