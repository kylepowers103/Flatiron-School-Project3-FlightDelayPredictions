{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_col(x):\n",
    "    # True pos = 1, True neg = 2, False pos = 3, false neg = 4\n",
    "    if (x['True'] == 1) & (x['predict'] > 0.5):\n",
    "        return 1\n",
    "    elif (x['True'] == 0) & (x['predict'] < 0.5):\n",
    "        return 2\n",
    "    elif (x['True'] == 0) & (x['predict'] > 0.5):\n",
    "        return 3\n",
    "    elif (x['True'] == 1) & (x['predict'] < 0.5):\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbours\n",
    "\n",
    "# training_features, test_features,training_target, test_target, = train_test_split(features, targets, test_size = 0.1, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, targets,test_size = .1,random_state=12)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic = SGDClassifier(loss='log', penalty='l2', early_stopping=True,\n",
    "#                          max_iter=10000, tol=1e-5, random_state=0)\n",
    "# pca = PCA()\n",
    "# forest_one = RandomForestClassifier(n_estimators=130, random_state=12)\n",
    "# pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "# # pipe = Pipeline(steps=[('pca', pca), ('forest', forest_one)])\n",
    "\n",
    "\n",
    "# X_digits = features\n",
    "# y_digits = targets\n",
    "\n",
    "# # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "# param_grid = {\n",
    "#     'pca__n_components': [70,75,90],\n",
    "#     'logistic__alpha': np.logspace(-4, 4, 5),\n",
    "    \n",
    "# }\n",
    "# search = GridSearchCV(pipe, param_grid, iid=False, cv=5,\n",
    "#                       return_train_score=False)\n",
    "# search.fit(X_digits, y_digits)\n",
    "\n",
    "\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# print(search.best_params_)\n",
    "# # Best parameter (CV score=0.832):\n",
    "# # {'logistic__alpha': 0.01, 'pca__n_components': 80}\n",
    "\n",
    "\n",
    "# # Plot the PCA spectrum\n",
    "# pca.fit(X_digits)\n",
    "\n",
    "# fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "# ax0.plot(pca.explained_variance_ratio_, linewidth=2)\n",
    "# ax0.set_ylabel('PCA explained variance')\n",
    "\n",
    "# ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "#             linestyle=':', label='n_components chosen')\n",
    "# ax0.legend(prop=dict(size=12))\n",
    "\n",
    "# # For each number of components, find the best classifier results\n",
    "# results = pd.DataFrame(search.cv_results_)\n",
    "# components_col = 'param_pca__n_components'\n",
    "# best_clfs = results.groupby(components_col).apply(\n",
    "#     lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "# best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "#                legend=False, ax=ax1)\n",
    "# ax1.set_ylabel('Classification accuracy (val)')\n",
    "# ax1.set_xlabel('n_components')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# pca = decomposition.PCA()\n",
    "# pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# X_digits = features\n",
    "# y_digits = targets\n",
    "\n",
    "# ###############################################################################\n",
    "# # Plot the PCA spectrum\n",
    "# pca.fit(X_digits)\n",
    "\n",
    "# plt.figure(1, figsize=(4, 3))\n",
    "# plt.clf()\n",
    "# plt.axes([.2, .2, .7, .7])\n",
    "# plt.plot(pca.explained_variance_, linewidth=2)\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('n_components')\n",
    "# plt.ylabel('explained_variance_')\n",
    "\n",
    "# ###############################################################################\n",
    "# # Prediction\n",
    "\n",
    "# n_components = [90, 100, 110,120]\n",
    "# Cs = np.logspace(-4, 4, 3)\n",
    "\n",
    "# #Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "\n",
    "# estimator = GridSearchCV(pipe,\n",
    "#                          dict(pca__n_components=n_components,\n",
    "#                               logistic__C=Cs))\n",
    "# estimator.fit(features, targets)\n",
    "\n",
    "# plt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,\n",
    "#             linestyle=':', label='n_components chosen')\n",
    "# plt.legend(prop=dict(size=12))\n",
    "# plt.show()\n",
    "\n",
    "# # Mean Absolute Error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# print(mean_absolute_error(y_test1, y_pred1))\n",
    "# # Mean Squared Error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# print(mean_squared_error(y_test1, y_pred1))\n",
    "# from sklearn.metrics import r2_score\n",
    "# print(r2_score(y_test1, y_pred1))\n",
    "# var_explained = pca.explained_variance_ratio_ #ratio of variance each PC explains\n",
    "# print(pd.Series(var_explained))\n",
    "# ###Since 29 components aren't necessary, the last 20 PCs will be disregarded \n",
    "# ###since they explain less than.01 of the variance\n",
    "# print(sum(var_explained[0:10]))\n",
    "\n",
    "# # Mean Absolute Error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# print(mean_absolute_error(y_test1, y_pred1))\n",
    "# # Mean Squared Error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# print(mean_squared_error(y_test1, y_pred1))\n",
    "# from sklearn.metrics import r2_score\n",
    "# print(r2_score(y_test1, y_pred1))\n",
    "# # feature importance\n",
    "# # for feature in zip(features_names, rf.feature_importances_):\n",
    "# #     print(feature)\n",
    "\n",
    "\n",
    "\n",
    "# ## changed to calculate just with depdelay\n",
    "# ##Convert y to set of classes\n",
    "\n",
    "\n",
    "\n",
    "# # y_ontime = y[(y <= 15) & (y >= 0)] # 0 <= y <= 15 is on time by FAA standards\n",
    "# # y_early = y[y < 0] # y < 0 is flight left early\n",
    "# # y_delay = y[(y > 15) & (y <= 60)] # 15 < y <= 60 we'll consider as delayed\n",
    "# # y_sig_delay = (y[y > 60]) # 60 < y we'll considered significantly delayed\n",
    "\n",
    "# # y_early = [\"y_early\"]*len(y_early)\n",
    "# # y_ontime = ['y_ontime']*len(y_ontime)\n",
    "# # y_delay = ['y_delay']*len(y_delay)\n",
    "# # y_sig_delay = ['y_sig_delay']*len(y_sig_delay)\n",
    "# # y = pd.DataFrame(y_early + y_ontime + y_delay + y_sig_delay)\n",
    "\n",
    "# # le = preprocessing.LabelEncoder()\n",
    "# # le.fit(y)\n",
    "# # # y = column(y, warn=True)\n",
    "# # y_new = le.transform(y)\n",
    "# # y_new.shape #(278220,)\n",
    "# # y_new\n",
    "# # y_new=y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train4, x_val4, y_train4, y_val4 = train_test_split(X_new, targets,test_size = .1,random_state=12)\n",
    "\n",
    "# logreg = LogisticRegression(fit_intercept = False, C = 1e12) #Starter code\n",
    "# # logreg = LinearRegression(normalize=True)\n",
    "# model = logreg.fit(x_train4,y_train4)\n",
    "\n",
    "# #Predict\n",
    "# y_pred4=model.predict(x_val4)\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(model.score(x_val4, y_val4)))\n",
    "# # print(classification_report(y_val4, y_pred4))\n",
    "# print(confusion_matrix(y_pred4,y_val4))\n",
    "# # Accuracy score\n",
    "# print('accuracy is',accuracy_score(y_pred4,y_val4))\n",
    "\n",
    "# Using X_new\n",
    "# Accuracy of logistic regression classifier on test set: 0.60\n",
    "# [[13074  1940]\n",
    "#  [ 9246  3562]]\n",
    "# accuracy is 0.5979440730357272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
